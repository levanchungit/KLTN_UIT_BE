# KLTN_UIT_BE Configuration File
# AI Backend for Transaction Classification - Optimized

# LLM Server Configuration (llama.cpp)
llm:
  base_url: "http://127.0.0.1:8080"
  api_key: "no-key-required"
  # Recommended: Use smaller model for faster inference
  model: "qwen2.5-1.5b-instruct-q4_0.gguf"
  # model: "qwen2.5-7b-instruct-q4_k_m.gguf"  # Slower but more accurate
  temperature: 0.0  # Deterministic output for caching
  max_tokens: 256   # Optimized: JSON output needs ~100-150 tokens
  timeout: 30       # Reduced from 60s

# FastAPI Server Configuration
server:
  host: "0.0.0.0"
  port: 8000
  debug: true
  cors_origins:
    - "http://localhost:8081"
    - "http://localhost:3000"
    - "http://localhost:19000"
    - "http://localhost:19006"
    - "exp://localhost:8081"
    - "exp://localhost:19000"
    - "exp://*"
    - "http://192.168.*.*:*"
    - "*"  # Allow all origins for development

# Application Configuration
app:
  default_categories:
    - "4G"
    - "Cafe"
    - "Di chuyển"
    - "Giáo dục"
    - "Giải trí"
    - "Hớt tóc"
    - "Khác"
    - "Mượn tiền"
    - "Mỹ phẩm chăm sóc da"
    - "Phiếu lương"
    - "Quà tặng"
    - "Sức khỏe"
    - "Trả nợ"
    - "Tạp phẩm"
    - "Đám tiệc"
  transaction_types:
    - "Thu nhập"
    - "Chi phí"
  supported_locales:
    - "vi-VN"
  default_currency: "VND"

# Validation Configuration
validation:
  min_amount: 0
  max_amount: 10000000000  # 10 tỷ VND
  confidence_min: 0.0
  confidence_max: 1.0

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
